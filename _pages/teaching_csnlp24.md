---
title: "ETH LRE Lab - Teaching"
layout: teaching
excerpt: "Teaching"
sitemap: false
permalink: /teaching_csnlp24
---

# Computational Semantics for Natural Language Processing
### <font color=gray>ETH Zürich, Spring Semester 2024</font>: [Course catalog](https://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=178278&semkez=2024S&ansicht=LEHRVERANSTALTUNGEN&lang=en)

___

## Course Description
This course presents an introduction to Natural language processing (NLP) with an emphasis on computational semantics i.e. the process of constructing and reasoning with meaning representations of natural language text.

The objective of the course is to learn about various topics in computational semantics and its importance in natural language processing methodology and research. Exercises and the project will be key parts of the course so the students will be able to gain hands-on experience with state-of-the-art techniques in the field.

___

### **Grading**
The final assessment will be a combination of a group paper presentation (10%), two graded exercises (40%) and the project (50%). There will be no written exams.

**Lectures:** Fri 14:00-16:00 (CAB G61)

**Discussion Sections:**  Fri 16:00-17:00

**Office Hour (assignment, project):** Please contact professor/TAs for appointment.


**Textbooks:**
We will not follow any particular textbook. We will draw material from a number of research papers and classes taught around the world.
However, the following textbooks would be useful:
1. [Introduction to Natural Language Processing by Jacob Eisenstein](https://www.amazon.de/Jacob-Eisenstein/dp/0262042843/ref=sr_1_1?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=30OMHV1C018JY&dchild=1&keywords=introduction+to+natural+language+processing&qid=1598878964&sprefix=introduction+to+na%2Caps%2C148&sr=8-1)
2. [Speech and Language Processing by Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/)

## News
**15.02**    Class website is online!

___

## Course Schedule

|:--|:--|:--|:--|:--|:--|
|&nbsp;<b>Lecture</b>|<b>Date</b>|<b>Description</b>|<b>Course Materials</b>| <b>Events</b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|Exercise TA|
|&nbsp;&nbsp;1|&nbsp;23.02&nbsp;&nbsp;&nbsp;&nbsp;|<b>Introduction</b>|[Diagnostic Quiz](https://polybox.ethz.ch/index.php/s/YCTThVpOd5Cu2AO) <br> [Answers to quiz](https://polybox.ethz.ch/index.php/s/7VPcHOmIxQD5AcX) <br> [Guidelines for Paper Presentation](https://docs.google.com/document/d/1LcAHXw9k2kxUhIMWKk-xaKUkx12eA91ahiZuxfsYfOQ/edit)|Presentation preference indication|
|&nbsp;&nbsp;2|&nbsp;01.03&nbsp;|<b>The Distributional Hypothesis and Word Vectors</b>|1. [Glove](https://nlp.stanford.edu/pubs/glove.pdf)||
|&nbsp;Voluntary |&nbsp;01.03&nbsp;| Matrix Calculus and Backpropagation|1. [CS231n notes on network architectures](http://cs231n.github.io/neural-networks-1/) <br> 2. [CS231n notes on backprop](http://cs231n.github.io/optimization-2/) <br> 3. [Learning Representations by Backpropagating Errors](http://www.iro.umontreal.ca/) <br> 4. [Derivatives, Backpropagation, and Vectorization](http://cs231n.stanford.edu/handouts/derivatives.pdf) <br> 5. [Yes you should understand backprop](https://medium.com/)||Shehzaad|
|&nbsp;&nbsp;3|&nbsp;08.03 &nbsp;|<b>Word Vectors 2, Word Senses and Sentence Vectors</b> <br><br> (Recursive and Recurrent Neural Networks)|1. [Unsupervised Word Sense Disambiguation Rivaling Supervised Methods](https://www.aclweb.org/anthology/P95-1026.pdf) <br> 2. [Improving Vector Space Word Representations Using Multilingual Correlation](https://www.aclweb.org/anthology/E14-1049.pdf) <br> 3. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078) ||
|&nbsp;Voluntary |&nbsp;08.03 &nbsp;|Final projects (Introduction and Guidelines)|1. [Guidelines](https://docs.google.com/document/d/1b5FNlXqXsMsld83lmoE8EFsHEEuHRmQEP_EPOyAkwAU/edit) <br> 2. [Suggested projects](https://docs.google.com/document/d/1b5FNlXqXsMsld83lmoE8EFsHEEuHRmQEP_EPOyAkwAU/edit)||Yifan|
|&nbsp;4| &nbsp;15.03&nbsp; | <b>NLU beyond a sentence</b> <br><br> Seq2Seq and Attention <br><br> Case Study: Sentence Similarity, Textual Entailment and Machine Comprehension |1. [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906) <br> 2. [Bidirectional Attention Flow for Machine Comprehension](https://arxiv.org/abs/1611.01603) ||
|&nbsp;Voluntary |&nbsp;15.03&nbsp;|Project rotation: <br> bring your project title; <br> find your supervised TAs|||All TAs|
|&nbsp;5|&nbsp;22.03&nbsp;| <b>Syntax and Predicate Argument Structures</b> <br><br> (Semantic Role Labelling, Frame Semantics, etc.)|1. [Stanford’s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task](https://www.aclweb.org/anthology/K17-3002.pdf) <br>2. [Grammar as a foreign language](https://papers.nips.cc/paper/2015/file/277281aada22045c03945dcb2ca6f2ec-Paper.pdf)|Assignment 1 released|
|&nbsp;Voluntary|&nbsp;22.03&nbsp;|Cluster usage (Guidelines)|||Shehzaad|
|&nbsp;<i>Easter</i>|&nbsp;29.03&nbsp;||||
|&nbsp;<i>Easter</i>|&nbsp;05.04&nbsp;||||
|&nbsp;6|&nbsp;12.04&nbsp;|<b>Predicate Argument Structures II</b> <br><br> (Semantic Role Labelling, Frame Semantics, etc.)|1.[Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling](https://aclanthology.org/P18-2058.pdf) <br> 2.[Frame-Semantic Parsing](https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00163)|Project proposal due|
|&nbsp;Voluntary|&nbsp;12.04&nbsp;|Project proposal discussion 1|Project feasiblity, topic, and proposal summary|[Schedule (TBD)]()|All TAs|
|&nbsp;7|&nbsp;19.04&nbsp;|<b>Modelling and tracking entities:</b> NER, coreference and information extraction (entity and relation extraction)|1. [End-to-end Neural Coreference Resolution](https://arxiv.org/abs/1707.07045) <br> 2. [Improving Coreference Resolution by Learning Entity-Level Distributed Representations](https://aclanthology.org/P16-1061/)||
|&nbsp;Voluntary|&nbsp;19.04&nbsp;|Project proposal discussion2 |Project feasiblity, topic, and proposal summary|[Schedule (TBD)]()|All TAs|
|&nbsp;8|&nbsp;26.04&nbsp;|<b>Formal Representations of Language Meaning</b>|1.[Compositional semantic parsing on semi-structured tables](https://arxiv.org/abs/1508.00305) <br> 2.[Supertagging With LSTMs](https://aclanthology.org/N16-1027/)|Assignment 1 due <br>Assignment 2 release <br>Project proposal grade out|
|&nbsp;Voluntary |&nbsp;26.04&nbsp;|Project proposal grade summary <br>Assignment 1 review (hint)|||All TAs|
|&nbsp;9|&nbsp;03.05&nbsp;|<b>Transformers and Contextual Word Representations</b> (BERT, etc.) <br><br> Guest lecture by Avinava Dubey (Google)|1. [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) (Only cover the idea of sparse attention: don’t need to cover turing completeness and the theoretical results)) <br> 2. [BERT rediscovers the classical NLP pipeline](https://arxiv.org/abs/1905.05950)||
|&nbsp;Voluntary|&nbsp;03.05&nbsp;|Optionla|schedule meeting with TA if necesary|||
|&nbsp;10|&nbsp;10.05&nbsp;|<b>Question Answering</b>|<br>1. [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/abs/1704.00051) <br> 2. [Latent Retrieval for Weakly Supervised Open Domain Question Answering](https://arxiv.org/abs/1906.00300)||
|&nbsp;Voluntary|&nbsp;10.05&nbsp;|Huggingface and Transformers|<br>1. [Huggingface](https://huggingface.co/)||Sankalan|
|&nbsp;11|&nbsp;17.05&nbsp;|<b>Natural Language Generation</b> <br><br> Case Study: Summarization and Conversation Modelling |1. [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) <br> 2. [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461) |Assignment 1 grade out|
|&nbsp;Voluntary|&nbsp;17.05&nbsp;|Assignment 1 grade summary <br> Project progress discussion 1 |Project progress, problems, whole storyline|[Schedule (TBD)]()|All TAs|
|&nbsp;12|&nbsp;24.05&nbsp;|<b>Language + {Knowledge, Vision, Action}</b>|1. [Knowledge Enhanced Contextual Word Representations](https://arxiv.org/abs/1909.04164) <br> 2. [VisualBERT: A Simple and Performant Baseline for Vision and Language](https://arxiv.org/abs/1908.03557)|Project mid-term report due|
|&nbsp;Voluntary|&nbsp;24.05&nbsp;|Project progress discussion 2|Project progress, problems, whole storyline|[Schedule (TBD)]()|All TAs|
|&nbsp;13|&nbsp;31.05&nbsp;|<b>Pragmatics</b>|1. [Pragmatic Language Interpretation as Probabilistic Inference](http://langcog.stanford.edu/papers_new/goodman-2016-underrev.pdf) <br> 2. [Rational speech act models of pragmatic reasoning in reference games](https://psyarxiv.com/f9y6b/)|Assignment 2 due|
|&nbsp;Voluntary|&nbsp;31.05&nbsp;|Assignment 2  review (hint)|||All TAs|
||&nbsp;21.06&nbsp;|||Assignment 2 grade out <br>Project report due|
||&nbsp;12.07&nbsp;||[Schedule (TBD)]()|Poster session|




___

## Assignment Submission Instructions

[Moodle](https://moodle-app2.let.ethz.ch/)

## Materials

-   [Lecture Slides & Student Presentation Slides (Moodle)](https://moodle-app2.let.ethz.ch/)
-   [Project Guidelines](https://docs.google.com/document/d/1b5FNlXqXsMsld83lmoE8EFsHEEuHRmQEP_EPOyAkwAU/edit)
-   [Assignments (Moodle)](https://moodle-app2.let.ethz.ch/)

___

## Contact

You can ask questions on [moodle](https://moodle-app2.let.ethz.ch/). Please post questions there, so others can see them and share in the discussion. If you have questions which are not of general interest, please don’t hesitate to contact us directly.

|:--|:--|
|Lecturer| [Mrinmaya Sachan](http://www.mrinmaya.io/)|
|Guest Lecturers|[Avinava Dubey]([https://research.google/people/ManzilZaheer/](https://sites.google.com/site/kumaravinavadubey/home)),&nbsp; [Alex Warstadt](Alex Warstadt),&nbsp; [Ethan Wilcox](https://wilcoxeg.github.io/)|
|Teaching Assistants| [Shehzaad Dhuliawala](https://people.cs.umass.edu/~sdhuliawala/),&nbsp; [Yifan Hou](https://yifan-h.github.io/),&nbsp; [Sankalan Pal Chowdhury](https://www.mrinmaya.io/team/#:~:text=Sankalan%20Pal%20Chowdhury),&nbsp; Tianyang Xu|


___
